本文章来源于：<https://github.com/Zeb-D/my-review> ，请star 强力支持，你的支持，就是我的动力。

[TOC]

------

### 背景

基于上篇文章[消息队列之主要MQ熟悉](../消息队列之主要MQ熟悉.md),这篇文章主要围绕当前主流MQ中间件的业务技术选型；

对于kafka，我们一般会用于大批量数据处理如日志上报等，我们也了解过[kafka数据流向图](../消息队列之主要MQ熟悉.md#kafka),这里将的是生产者如何往Kafka broker丢数据；

此时我们可以抛出一个**疑问**：

IO磁盘读写不是性能低吗？kafka是怎么做到高吞吐低延迟的高并发、高性能的？

### 写入分析

也许大家会想到我们操作数据，其实是往内存写，然后内存再把数据刷到磁盘中；

首先Kafka是基于操作系统的页缓存来实现文件写入的。

操作系统本身有一层缓存，叫做page cache，是在内存里的缓存，我们也可以称之为os cache，意思就是操作系统自己管理的缓存。

你在写入磁盘文件的时候，可以直接写入这个os cache里，也就是仅仅写入内存中，接下来由操作系统自己决定什么时候把os cache里的数据真的刷入磁盘文件中。

**简单概括一点**，kafka写数据这里相当于是在写内存

我们也知道kafka是使用scala写的，那它不可避免使用了JVM操作，写数据这里会有顺序的，虽然有支持各种RandomAccess 接口【随机访问】，这种随机访问会带来内存定位磁盘位置的损耗，然而，kafka的数据是必须顺序性的；

kafka追加文件末尾按照顺序的方式来写数据的话，那么这种磁盘顺序写的性能基本上可以跟写内存的性能本身也是差不多的。

基于以上两点，基本上能保证kafka在写入数据时候，单条数据处理速度是非常快的；

### 读数据分析

从Kafka里我们经常要消费数据，那么消费的时候实际上就是要从kafka的磁盘文件里读取某条数据然后发送给下游的消费者；

如果频繁的从磁盘读数据然后发给消费者，性能瓶颈在哪里呢？

我们开始普通的理解在没看kafka源码前：

#### 蒙眼揣测

很简单的从磁盘读数据发送给下游的消费者 大概过程如下所示：

先看看要读的数据在不在os cache里，如果不在的话就从磁盘文件里读取数据后放入os cache。

接着从操作系统的os cache里**拷贝**数据到应用程序进程的缓存里，

再从应用程序进程的缓存里**拷贝**数据到操作系统层面的Socket缓存里，最后从Socket缓存里提取数据后发送到网卡，最后发送出去给下游消费。

#### 延伸分析

这里就会发生用户进程、系统守护进程、Socket进程 之间数据多重拷贝，其实Java是提供了零拷贝技术，使用[内存磁盘映射]()，基于NIO之**channel** 的

> MappedByteBuffer buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, length)
>
> 这个length 可以简单的理解成kafka的offset变量

通过零拷贝技术，就不需要把os cache里的数据拷贝到应用缓存，再从应用缓存拷贝到Socket缓存了，两次拷贝都省略了，所以叫做零拷贝。

对Socket缓存仅仅就是拷贝数据的描述符过去，然后数据就直接从os cache中发送到网卡上去了，这个过程大大的提升了数据消费时读取文件数据的性能。

而且大家会注意到，在从磁盘读数据的时候，会先看看os cache内存中是否有，如果有的话，其实读数据都是直接读内存的。

如果kafka集群经过良好的调优，大家会发现大量的数据都是直接写入os cache中，然后读数据的时候也是从os cache中读。

相当于是Kafka完全基于内存提供数据的写和读了，所以这个整体性能会极其的高。

------

### 总结

对于kafka的探索正在持续中，本篇文章后续可能会重写；

有兴趣的小伙伴可以延伸阅读 [CPU  cache](../../..//linux/CPU Cache 深入分析#cpu-cache介绍)

#### Kafka特性

1. 数据磁盘持久化：消息不在内存中cache，直接写入到磁盘，充分利用磁盘的顺序读写性能
2. zero-copy：减少IO操作步骤
3. 数据批量发送
4. 数据压缩
5. Topic划分为多个partition，提高parallelism

